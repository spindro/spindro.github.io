[{"authors":["Indro Spinelli","Simone Scardapane","Amir Hussain","Aurelio Uncini"],"categories":null,"content":"","date":1617228000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1617228000,"objectID":"44a96ac0bd35081db430821af32d29d3","permalink":"https://spindro.github.io/publication/fairdrop/","publishdate":"2021-04-01T00:00:00+02:00","relpermalink":"/publication/fairdrop/","section":"publication","summary":"Graph representation learning has become a ubiquitous component in many scenarios, ranging from social network analysis to energy forecasting in smart grids. In several applications, ensuring the fairness of the node (or graph) representations with respect to some protected attributes is crucial for their correct deployment. Yet, fairness in graph deep learning remains under-explored, with few solutions available. In particular, the tendency of similar nodes to cluster on several real-world graphs (i.e., homophily) can dramatically worsen the fairness of these procedures. In this paper, we propose a biased edge dropout algorithm (FairDrop) to counter-act homophily and improve fairness in graph representation learning. FairDrop can be plugged in easily on many existing algorithms, is efficient, adaptable, and can be combined with other fairness-inducing solutions. After describing the general algorithm, we demonstrate its application on two benchmark tasks, specifically, as a random walk model for producing node embeddings, and to a graph convolutional network for link prediction. We prove that the proposed algorithm can successfully improve the fairness of all models up to a small or negligible drop in accuracy, and compares favourably with existing state-of-the-art solutions. In an ablation study, we demonstrate that our algorithm can flexibly interpolate between biasing towards fairness and an unbiased edge dropout. Furthermore, to better evaluate the gains, we propose a new dyadic group definition to measure the bias of a link prediction task when paired with group-based fairness metrics. In particular, we extend the metric used to measure the bias in the node embeddings to take into account the graph structure.","tags":null,"title":"Biased Edge Dropout for Enhancing Fairness in Graph Representation Learning","type":"publication"},{"authors":["Simone Scardapane","Indro Spinelli","Paolo Di Lorenzo"],"categories":null,"content":"","date":1606777200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606777200,"objectID":"6c0e073df9e28f7d93590bf460e9d4fe","permalink":"https://spindro.github.io/publication/dgcn/","publishdate":"2020-12-01T00:00:00+01:00","relpermalink":"/publication/dgcn/","section":"publication","summary":"The aim of this work is to develop a fully-distributed algorithmic framework for training graph convolutional networks (GCNs). The proposed method is able to exploit the meaningful relational structure of the input data, which are collected by a set of agents that communicate over a sparse network topology. After formulating the centralized GCN training problem, we first show how to make inference in a distributed scenario where the underlying data graph is split among different agents. Then, we propose a distributed gradient descent procedure to solve the GCN training problem. The resulting model distributes computation along three lines: during inference, during back-propagation, and during optimization. Convergence to stationary solutions of the GCN training problem is also established under mild conditions. Finally, we propose an optimization criterion to design the communication topology between agents in order to match with the graph describing data relationships. A wide set of numerical results validate our proposal. To the best of our knowledge, this is the first work combining graph convolutional neural networks with distributed optimization.","tags":null,"title":"Distribuited Graph Convolutional Network","type":"publication"},{"authors":["Indro Spinelli","Simone Scardapane","Aurelio Uncini"],"categories":null,"content":"","date":1604185200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1604185200,"objectID":"a4616b89fa55c4b66fb4268c95d30113","permalink":"https://spindro.github.io/publication/apgcn/","publishdate":"2020-11-01T00:00:00+01:00","relpermalink":"/publication/apgcn/","section":"publication","summary":"Graph convolutional networks (GCNs) are a family of neural network models that perform inference on graph data by interleaving vertex-wise operations and message-passing exchanges across nodes. Concerning the latter, two key questions arise: (i) how to design a differentiable exchange protocol (e.g., a 1-hop Laplacian smoothing in the original GCN), and (ii) how to characterize the trade-off in complexity with respect to the local updates. In this paper, we show that state-of-the-art results can be achieved by adapting the number of communication steps independently at every node. In particular, we endow each node with a halting unit (inspired by Graves' adaptive computation time) that after every exchange decides whether to continue communicating or not. We show that the proposed adaptive propagation GCN (AP-GCN) achieves superior or similar results to the best proposed models so far on a number of benchmarks, while requiring a small overhead in terms of additional parameters. We also investigate a regularization term to enforce an explicit trade-off between communication and accuracy. The code for the AP-GCN experiments is released as an open-source library.","tags":null,"title":"Adaptive Propagation Graph Convolutional Network","type":"publication"},{"authors":["Indro Spinelli","Simone Scardapane","Aurelio Uncini"],"categories":null,"content":"","date":1598911200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598911200,"objectID":"25f276c66af4d75b0d2816f0f3e6aeb3","permalink":"https://spindro.github.io/publication/ginn/","publishdate":"2020-09-01T00:00:00+02:00","relpermalink":"/publication/ginn/","section":"publication","summary":"Missing data imputation (MDI) is a fundamental problem in many scientific disciplines. Popular methods for MDI use global statistics computed from the entire data set (e.g., the feature-wise medians), or build predictive models operating independently on every instance. In this paper we propose a more general framework for MDI, leveraging recent work in the field of graph neural networks (GNNs). We formulate the MDI task in terms of a graph denoising autoencoder, where each edge of the graph encodes the similarity between two patterns. A GNN encoder learns to build intermediate representations for each example by interleaving classical projection layers and locally combining information between neighbors, while another decoding GNN learns to reconstruct the full imputed data set from this intermediate embedding. In order to speed-up training and improve the performance, we use a combination of multiple losses, including an adversarial loss implemented with the Wasserstein metric and a gradient penalty. We also explore a few extensions to the basic architecture involving the use of residual connections between layers, and of global statistics computed from the data set to improve the accuracy. On a large experimental evaluation, we show that our method robustly outperforms state-of-the-art approaches for MDI, especially for large percentages of missing values.","tags":null,"title":"Missing Data Imputation with Adversarially-trained Graph Convolutional Networks","type":"publication"},{"authors":null,"categories":["Graph Neural Network","Seminar"],"content":"Here you can find an introduction to the world of graph neural networks (GNN for short). This family of models is able process graph structured data and solve many interesting tasks.\n","date":1575504000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575504000,"objectID":"386c672f1a1e981656cdd956a5d5d30f","permalink":"https://spindro.github.io/post/gnn/","publishdate":"2019-12-05T00:00:00Z","relpermalink":"/post/gnn/","section":"post","summary":"Here you can find an introduction to the world of graph neural networks (GNN for short). This family of models is able process graph structured data and solve many interesting tasks.","tags":["graph neural networks","ginn","ggnn","machine learning","neural networks","open source","graph","artificial intelligence","knowledge base"],"title":"Seminar on Graph Neural Networks","type":"post"},{"authors":["Indro Spinelli","Simone Scardapane","Michele Scarpiniti","Aurelio Uncini"],"categories":null,"content":"","date":1561932000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561932000,"objectID":"5aacc85d291cb6ec4ae5135757536321","permalink":"https://spindro.github.io/publication/ggnn/","publishdate":"2019-07-01T00:00:00+02:00","relpermalink":"/publication/ggnn/","section":"publication","summary":"Recently, data augmentation in the semi-supervised regime, where unlabeled data vastly outnumbers labeled data, has received a considerable attention. In this paper, we describe an efficient technique for this task, exploiting a recent framework we proposed for missing data imputation called graph imputation neural network (GINN). The key idea is to leverage both supervised and unsupervised data to build a graph of similarities between points in the dataset. Then, we augment the dataset by severely damaging a few of the nodes (up to 80% of their features), and reconstructing them using a variation of GINN. On several benchmark datasets, we show that our method can obtain significant improvements compared to a fully-supervised model, and we are able to augment the datasets up to a factor of 10x. This points to the power of graph-based neural networks to represent structural affinities in the samples for tasks of data reconstruction and augmentation. ","tags":null,"title":"Efficient data augmentation using graph imputation neural networks","type":"publication"},{"authors":null,"categories":["PLVS","SLAM"],"content":"We recently released a teaser of PLVS in action. Here you can find more info and a lot of videos of PLVS showing its capabilities on many different datasets. PLVS is still a work in progress but the software will be released as open-source with our outcoming paper very soon!\n","date":1538352000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538352000,"objectID":"4a0d3166cda1525bd4a6121bf25bdea4","permalink":"https://spindro.github.io/post/plvs/","publishdate":"2018-10-01T00:00:00Z","relpermalink":"/post/plvs/","section":"post","summary":"We recently released a teaser of PLVS in action. Here you can find more info and a lot of videos of PLVS showing its capabilities on many different datasets. PLVS is still a work in progress but the software will be released as open-source with our outcoming paper very soon!","tags":["3D reconstruction","augmented reality","computer vision","image processig","mapping","open source","perception","robotics","sensors","SLAM","TRADR"],"title":"PLVS Teaser","type":"post"},{"authors":["Luigi Freda","Indro Spinelli","Fiora Pirri"],"categories":null,"content":"","date":1537308000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1537308000,"objectID":"bab6dcd18d82ec24e534c6a86cf1eedb","permalink":"https://spindro.github.io/publication/plvs/","publishdate":"2018-09-19T00:00:00+02:00","relpermalink":"/publication/plvs/","section":"publication","summary":"PLVS is a real-time system which leverages sparse RGB-D and Stereo SLAM, volumetric mapping and 3D unsupervised incremental segmentation. PLVS stands for Points, Lines, Volumetric mapping and Segmentation. The system can run entirely on CPU or can profit by available GPU computational resources for some specific tasks. The underlying SLAM module is sparse and keyframe-based. It relies on the extraction and tracking of keypoints and keylines. Different volumetric mapping methods are supported and integrated in PLVS. A novel “reprojection” error is proposed for bundle-adjusting line segments. This error allows to better stabilize the position estimates of the mapped line segment endpoints and improves SLAM performances. An incremental segmentation method is implemented and integrated in the PLVS framework. ","tags":["computer vision","robotics","SLAM","TRADR"],"title":"PLVS: An Open-Source RGB-D and Stereo SLAM System with Keypoints, Keylines, Volumetric Mapping and 3D Incremental Segmentation","type":"publication"},{"authors":null,"categories":["EU Project","TRADR","robotics","SLAM"],"content":" This is the first post of my personal page and in some sense, the story the beginning of my interest in research. I had the privilege to collaborate as a bachelor and later master student to an European project TRADR: Long-Term Human-Robot Teaming for Disaster Response. It has not been always easy to make this intern at the Alcor lab coexist with my ordinary studies, but was worth it. I\u0026rsquo;ve learned a lot of stuff, travelled as much and made new connections.\nThe video crew of the Italians Firefighters, the Vigili del Fuoco captured various moments of the final year review project held in an industrial site near Venice.\n  This is just the last of many activities done for the project in different countries, including: two reviews, a robotics summer school in Utrecht (TNO), and a demo for the European Robotics League held in Piombino.\n","date":1537142400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1537142400,"objectID":"aaa132a6b5d973ae307e1eae8b8417af","permalink":"https://spindro.github.io/post/tradr/","publishdate":"2018-09-17T00:00:00Z","relpermalink":"/post/tradr/","section":"post","summary":"This is the first post of my personal page and in some sense, the story the beginning of my interest in research. I had the privilege to collaborate as a bachelor and later master student to an European project TRADR: Long-Term Human-Robot Teaming for Disaster Response. It has not been always easy to make this intern at the Alcor lab coexist with my ordinary studies, but was worth it. I\u0026rsquo;ve learned a lot of stuff, travelled as much and made new connections.","tags":["EU Project","TRADR","robotics","SLAM"],"title":"TRADR experience","type":"post"},{"authors":null,"categories":["Graph Neural Network","Seminar"],"content":"Reacently I had the pleasure of talking about graphs and fairness at \u0026ldquo;Università della Svizzera Italiana\u0026rdquo;. The talk was hosted by the Graph Machine Learning Group of Prof. Cesare Alippi and organized by Daniele Grattarola. For a buch of slides look Here.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"3f8923d8a5ed2871ccd36fb783eb0baf","permalink":"https://spindro.github.io/post/gnn/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/post/gnn/","section":"post","summary":"Reacently I had the pleasure of talking about graphs and fairness at \u0026ldquo;Università della Svizzera Italiana\u0026rdquo;. The talk was hosted by the Graph Machine Learning Group of Prof. Cesare Alippi and organized by Daniele Grattarola. For a buch of slides look Here.","tags":["graph neural networks","fairdrop","fairness","machine learning","neural networks"],"title":"FairDrop @ USI ","type":"post"}]